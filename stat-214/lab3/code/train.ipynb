{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcdb9fe-87b3-4a4f-aad1-db7f04f1418e",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "616fd306-e54b-422e-9059-1ca83eb86ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data import TextDataset\n",
    "from encoder import Encoder\n",
    "from train_encoder import train_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9a472a5-5b94-4ca2-a4f8-1536c7ab20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43a9ab45-c63d-4c41-a6e7-28cc3a062d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3903374/1170580056.py:5: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
      "  raw_texts = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "## open the data\n",
    "with open(\"../data/raw_text.pkl\", \"rb\") as f:\n",
    "    raw_texts = pickle.load(f)\n",
    "\n",
    "# Combine all story content into one big list of strings\n",
    "all_texts = []\n",
    "\n",
    "# Pick a sample story\n",
    "sample_story = raw_texts['avatar']\n",
    "all_stories = {}  # Dict[story_id: str]\n",
    "\n",
    "for story_id, sequence in raw_texts.items():\n",
    "    try:\n",
    "        full_story = \" \".join(sequence.data)\n",
    "        all_stories[story_id] = full_story\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {story_id}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a99308-be04-4925-b422-dd4bd40669b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "story_ids = list(all_stories.keys())\n",
    "\n",
    "# 2) split IDs\n",
    "train_ids, val_ids = train_test_split(\n",
    "    story_ids,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3) build lists of strings\n",
    "train_texts = [all_stories[sid] for sid in train_ids]\n",
    "val_texts   = [all_stories[sid] for sid in val_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8db7dbc4-969e-4bfa-8614-90089b7e46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer    = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "train_ds      = TextDataset(train_texts, tokenizer, max_len=128)\n",
    "val_ds        = TextDataset(val_texts,   tokenizer, max_len=128)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=1, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=1, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce18b910-0e94-46ba-aa34-1388a4168ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      " Training with lr=0.0005,layers=2,hs=128\n",
      "Epoch 1/35 — train: 10.3398, val: 10.0106\n",
      "Epoch 2/35 — train: 10.0185, val: 9.9075\n",
      "Epoch 3/35 — train: 9.6449, val: 9.5353\n",
      "Epoch 4/35 — train: 9.3383, val: 9.2914\n",
      "Epoch 5/35 — train: 8.9953, val: 8.8622\n",
      "Epoch 6/35 — train: 8.6455, val: 8.7619\n",
      "Epoch 7/35 — train: 8.2683, val: 8.4776\n",
      "Epoch 8/35 — train: 8.0058, val: 8.1878\n",
      "Epoch 9/35 — train: 7.7112, val: 8.1268\n",
      "Epoch 10/35 — train: 7.4238, val: 7.6349\n",
      "Epoch 11/35 — train: 7.2199, val: 7.4491\n",
      "Epoch 12/35 — train: 7.1084, val: 7.2637\n",
      "Epoch 13/35 — train: 6.8956, val: 7.4326\n",
      "Epoch 14/35 — train: 6.7210, val: 7.5106\n",
      "Epoch 15/35 — train: 6.6108, val: 7.3105\n",
      "Epoch 16/35 — train: 6.3265, val: 7.0123\n",
      "Epoch 17/35 — train: 6.6248, val: 7.0932\n",
      "Epoch 18/35 — train: 6.4312, val: 7.1567\n",
      "Epoch 19/35 — train: 6.3707, val: 6.9545\n",
      "Epoch 20/35 — train: 6.4515, val: 6.8379\n",
      "Epoch 21/35 — train: 6.2690, val: 6.9824\n",
      "Epoch 22/35 — train: 6.2269, val: 6.7614\n",
      "Epoch 23/35 — train: 6.3649, val: 6.9558\n",
      "Epoch 24/35 — train: 6.3530, val: 6.7203\n",
      "Epoch 25/35 — train: 6.5008, val: 6.7735\n",
      "Epoch 26/35 — train: 6.4008, val: 7.0373\n",
      "Epoch 27/35 — train: 6.5101, val: 6.9032\n",
      "Epoch 28/35 — train: 6.3343, val: 7.1223\n",
      "Epoch 29/35 — train: 6.0980, val: 7.1373\n",
      "Epoch 30/35 — train: 6.2293, val: 7.3312\n",
      "Epoch 31/35 — train: 6.2057, val: 7.0756\n",
      "Epoch 32/35 — train: 6.0902, val: 7.2279\n",
      "Epoch 33/35 — train: 6.1879, val: 7.2255\n",
      "Epoch 34/35 — train: 6.2840, val: 6.8936\n",
      "Epoch 35/35 — train: 6.2088, val: 6.7146\n",
      "Saved model to: saved_models/encoder_lr0.0005_layers2_hs128.pt\n",
      "\n",
      " Training with lr=0.0005,layers=4,hs=256\n",
      "Epoch 1/35 — train: 10.1712, val: 9.7413\n",
      "Epoch 2/35 — train: 9.3187, val: 9.0203\n",
      "Epoch 3/35 — train: 8.8311, val: 8.6038\n",
      "Epoch 4/35 — train: 8.3131, val: 8.0305\n",
      "Epoch 5/35 — train: 7.6681, val: 7.9070\n",
      "Epoch 6/35 — train: 7.1382, val: 7.6668\n",
      "Epoch 7/35 — train: 6.8849, val: 7.2443\n",
      "Epoch 8/35 — train: 6.6777, val: 7.1415\n",
      "Epoch 9/35 — train: 6.5603, val: 7.1788\n",
      "Epoch 10/35 — train: 6.6015, val: 6.9158\n",
      "Epoch 11/35 — train: 6.5066, val: 6.9723\n",
      "Epoch 12/35 — train: 6.4503, val: 6.8318\n",
      "Epoch 13/35 — train: 6.3354, val: 7.0181\n",
      "Epoch 14/35 — train: 6.7217, val: 7.0887\n",
      "Epoch 15/35 — train: 6.4345, val: 6.9462\n",
      "Epoch 16/35 — train: 6.3817, val: 7.0604\n",
      "Epoch 17/35 — train: 6.3614, val: 7.2656\n",
      "Epoch 18/35 — train: 6.3921, val: 6.8062\n",
      "Epoch 19/35 — train: 6.1900, val: 7.2803\n",
      "Epoch 20/35 — train: 6.3841, val: 7.0508\n",
      "Epoch 21/35 — train: 6.2705, val: 7.1005\n",
      "Epoch 22/35 — train: 6.3419, val: 6.6817\n",
      "Epoch 23/35 — train: 6.1367, val: 7.1408\n",
      "Epoch 24/35 — train: 6.3596, val: 7.4033\n",
      "Epoch 25/35 — train: 6.2345, val: 6.3984\n",
      "Epoch 26/35 — train: 6.2115, val: 7.0123\n",
      "Epoch 27/35 — train: 6.3151, val: 6.9019\n",
      "Epoch 28/35 — train: 6.0174, val: 7.0614\n",
      "Epoch 29/35 — train: 6.2393, val: 7.0846\n",
      "Epoch 30/35 — train: 6.1324, val: 6.8182\n",
      "Epoch 31/35 — train: 6.0723, val: 6.5895\n",
      "Epoch 32/35 — train: 6.2453, val: 6.8811\n",
      "Epoch 33/35 — train: 6.0837, val: 7.0613\n",
      "Epoch 34/35 — train: 6.1948, val: 7.0135\n",
      "Epoch 35/35 — train: 6.2002, val: 6.6814\n",
      "Saved model to: saved_models/encoder_lr0.0005_layers4_hs256.pt\n",
      "\n",
      " Training with lr=0.0001,layers=4,hs=256\n",
      "Epoch 1/35 — train: 10.3086, val: 10.1885\n",
      "Epoch 2/35 — train: 10.1251, val: 9.9467\n",
      "Epoch 3/35 — train: 9.9410, val: 9.9765\n",
      "Epoch 4/35 — train: 9.6958, val: 9.5771\n",
      "Epoch 5/35 — train: 9.6225, val: 9.4031\n",
      "Epoch 6/35 — train: 9.3683, val: 9.3930\n",
      "Epoch 7/35 — train: 9.1038, val: 9.1455\n",
      "Epoch 8/35 — train: 9.0835, val: 8.9430\n",
      "Epoch 9/35 — train: 8.8894, val: 8.9843\n",
      "Epoch 10/35 — train: 8.7941, val: 8.7864\n",
      "Epoch 11/35 — train: 8.8312, val: 8.7809\n",
      "Epoch 12/35 — train: 8.6029, val: 8.6725\n",
      "Epoch 13/35 — train: 8.4628, val: 8.6124\n",
      "Epoch 14/35 — train: 8.3332, val: 8.2752\n",
      "Epoch 15/35 — train: 8.0769, val: 8.4224\n",
      "Epoch 16/35 — train: 8.0365, val: 8.2905\n",
      "Epoch 17/35 — train: 7.8682, val: 8.0300\n",
      "Epoch 18/35 — train: 7.7693, val: 8.1052\n",
      "Epoch 19/35 — train: 7.5975, val: 7.7758\n",
      "Epoch 20/35 — train: 7.6037, val: 7.8464\n",
      "Epoch 21/35 — train: 7.5221, val: 7.8268\n",
      "Epoch 22/35 — train: 7.3172, val: 7.7317\n",
      "Epoch 23/35 — train: 7.2646, val: 7.6492\n",
      "Epoch 24/35 — train: 7.1413, val: 7.8592\n",
      "Epoch 25/35 — train: 7.2911, val: 7.5623\n",
      "Epoch 26/35 — train: 7.0437, val: 7.5483\n",
      "Epoch 27/35 — train: 7.0257, val: 7.3186\n",
      "Epoch 28/35 — train: 6.9394, val: 7.1134\n",
      "Epoch 29/35 — train: 6.9332, val: 7.2488\n",
      "Epoch 30/35 — train: 6.8316, val: 7.5579\n",
      "Epoch 31/35 — train: 6.7660, val: 7.1123\n",
      "Epoch 32/35 — train: 6.7854, val: 7.1891\n",
      "Epoch 33/35 — train: 6.6860, val: 7.1030\n",
      "Epoch 34/35 — train: 6.6692, val: 7.1084\n",
      "Epoch 35/35 — train: 6.5659, val: 7.5426\n",
      "Saved model to: saved_models/encoder_lr0.0001_layers4_hs256.pt\n",
      "\n",
      " Training with lr=0.0001,layers=6,hs=512\n",
      "Epoch 1/35 — train: 10.1446, val: 9.7865\n",
      "Epoch 2/35 — train: 9.5175, val: 9.3108\n",
      "Epoch 3/35 — train: 9.2040, val: 9.2967\n",
      "Epoch 4/35 — train: 8.8822, val: 8.8826\n",
      "Epoch 5/35 — train: 8.6589, val: 8.4618\n",
      "Epoch 6/35 — train: 8.2898, val: 8.4070\n",
      "Epoch 7/35 — train: 8.2558, val: 8.2844\n",
      "Epoch 8/35 — train: 8.0098, val: 7.8978\n",
      "Epoch 9/35 — train: 7.9298, val: 7.8203\n",
      "Epoch 10/35 — train: 7.4000, val: 7.9928\n",
      "Epoch 11/35 — train: 7.3929, val: 7.6342\n",
      "Epoch 12/35 — train: 7.2795, val: 7.4842\n",
      "Epoch 13/35 — train: 7.0433, val: 7.3625\n",
      "Epoch 14/35 — train: 6.7627, val: 7.2195\n",
      "Epoch 15/35 — train: 6.7891, val: 7.1736\n",
      "Epoch 16/35 — train: 6.7515, val: 7.1435\n",
      "Epoch 17/35 — train: 6.7136, val: 7.1008\n",
      "Epoch 18/35 — train: 6.5229, val: 6.7059\n",
      "Epoch 19/35 — train: 6.4584, val: 6.9236\n",
      "Epoch 20/35 — train: 6.3403, val: 6.5134\n",
      "Epoch 21/35 — train: 6.4818, val: 7.0484\n",
      "Epoch 22/35 — train: 6.5097, val: 6.9549\n",
      "Epoch 23/35 — train: 6.3017, val: 7.1105\n",
      "Epoch 24/35 — train: 6.5612, val: 6.6564\n",
      "Epoch 25/35 — train: 6.2942, val: 6.8485\n",
      "Epoch 26/35 — train: 6.2731, val: 6.8999\n",
      "Epoch 27/35 — train: 6.0628, val: 6.9054\n",
      "Epoch 28/35 — train: 6.3089, val: 7.1250\n",
      "Epoch 29/35 — train: 6.6296, val: 7.3585\n",
      "Epoch 30/35 — train: 6.3520, val: 6.8882\n",
      "Epoch 31/35 — train: 6.2641, val: 6.7073\n",
      "Epoch 32/35 — train: 6.4635, val: 6.9761\n",
      "Epoch 33/35 — train: 6.1529, val: 6.2517\n",
      "Epoch 34/35 — train: 6.1553, val: 7.0091\n",
      "Epoch 35/35 — train: 6.0614, val: 6.7681\n",
      "Saved model to: saved_models/encoder_lr0.0001_layers6_hs512.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from encoder import Encoder\n",
    "from train_encoder import train_bert\n",
    "import os\n",
    "\n",
    "\n",
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True) \n",
    "\n",
    "# ─── 1) Define your hyper‑parameter grid ──────────────────────────────────────\n",
    "configs = [\n",
    "    {\"lr\": 5e-4, \"num_layers\": 2, \"hidden_size\": 128},\n",
    "    {\"lr\": 5e-4, \"num_layers\": 4, \"hidden_size\": 256},\n",
    "    {\"lr\": 1e-4, \"num_layers\": 4, \"hidden_size\": 256},\n",
    "    {\"lr\": 1e-4, \"num_layers\": 6, \"hidden_size\": 512},\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "results = {}  # Stores loss for each config\n",
    "\n",
    "\n",
    "# ─── 2) Loop over configs ─────────────────────────────────────────────────\n",
    "\n",
    "for cfg in configs:\n",
    "    config_str = f\"lr={cfg['lr']},layers={cfg['num_layers']},hs={cfg['hidden_size']}\"\n",
    "    print(f\"\\n Training with {config_str}\")\n",
    "\n",
    "    # Instantiate encoder with the cfg\n",
    "    model = Encoder(\n",
    "        vocab_size=tokenizer.vocab_size,\n",
    "        hidden_size=cfg[\"hidden_size\"],\n",
    "        num_heads=4,  # fixed for now\n",
    "        num_layers=cfg[\"num_layers\"],\n",
    "        intermediate_size=cfg[\"hidden_size\"] * 2,\n",
    "        max_len=128\n",
    "    ).to(device)\n",
    "\n",
    "    # Call training loop\n",
    "    model, train_losses, val_losses = train_bert(\n",
    "        model=model,\n",
    "        train_dataloader=train_loader,\n",
    "        val_dataloader=val_loader,\n",
    "        tokenizer=tokenizer,\n",
    "        epochs=35, #40, can be tuned\n",
    "        lr=cfg[\"lr\"],\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # Store losses\n",
    "    results[config_str] = (train_losses, val_losses)\n",
    "\n",
    "    # Save model to saved_models folder\n",
    "    filename = f\"encoder_lr{cfg['lr']}_layers{cfg['num_layers']}_hs{cfg['hidden_size']}.pt\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Saved model to: {save_path}\")\n",
    "\n",
    "with open(\"mlm_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfba410e-4dfb-4776-8be3-bf00e86339a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mlm_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fe4576a-96e1-4c54-95a2-3d04d66590fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: loss_plots/loss_lr_0_0005_layers_2_hs_128.png\n",
      "Saved: loss_plots/loss_lr_0_0005_layers_4_hs_256.png\n",
      "Saved: loss_plots/loss_lr_0_0001_layers_4_hs_256.png\n",
      "Saved: loss_plots/loss_lr_0_0001_layers_6_hs_512.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# ─── Load results from file ────────────────────────────────────────────────\n",
    "with open(\"mlm_results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# ─── Create output directory ───────────────────────────────────────────────\n",
    "os.makedirs(\"loss_plots\", exist_ok=True)\n",
    "\n",
    "# ─── Plot each config separately ───────────────────────────────────────────\n",
    "for config_str, (train, val) in results.items():\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(train, label=\"Train Loss\")\n",
    "    plt.plot(val, label=\"Validation Loss\", linestyle=\"--\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Loss Curve — {config_str}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Format filename safely\n",
    "    safe_name = config_str.replace(\"=\", \"_\").replace(\",\", \"_\").replace(\".\", \"_\")\n",
    "    path = f\"loss_plots/loss_{safe_name}.png\"\n",
    "    plt.savefig(path)\n",
    "    plt.close()  # Close figure to avoid overlapping\n",
    "\n",
    "    print(f\"Saved: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9866abe9-5145-4773-85a2-8cbf9f120d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: loss_plots/loss_lr_0_0005_comparison.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load results\n",
    "with open(\"mlm_results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "os.makedirs(\"loss_plots\", exist_ok=True)\n",
    "\n",
    "# Filter configs with lr = 5e-4\n",
    "configs_to_plot = [k for k in results if \"lr=0.0005\" in k]\n",
    "configs_to_plot.sort()  # consistent order\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 5), sharey=True)\n",
    "\n",
    "for ax, config_str in zip(axes, configs_to_plot):\n",
    "    train, val = results[config_str]\n",
    "    ax.plot(train, label=\"Train Loss\")\n",
    "    ax.plot(val, label=\"Validation Loss\", linestyle=\"--\")\n",
    "    ax.set_title(config_str.replace(\"lr=\", \"lr=\").replace(\",\", \"\\n\"))  # multiline title\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.grid(True)\n",
    "    if ax is axes[0]:\n",
    "        ax.set_ylabel(\"Loss\")\n",
    "    ax.legend()\n",
    "\n",
    "fig.suptitle(\"Training vs Validation Loss (lr=5e-4)\")\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])  # leave space for suptitle\n",
    "\n",
    "\n",
    "save_path = \"loss_plots/loss_lr_0_0005_comparison.png\"\n",
    "plt.savefig(save_path,dpi=600)\n",
    "plt.close()\n",
    "print(f\"Saved: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c447fc99-6894-4c11-98cb-8590d598eee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Saved best model loss plot to: loss_plots/best_model_loss.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Load results\n",
    "with open(\"mlm_results.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "os.makedirs(\"loss_plots\", exist_ok=True)\n",
    "\n",
    "# Target config (best model)\n",
    "target_config = \"lr=0.0001,layers=6,hs=512\"\n",
    "train, val = results[target_config]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train, label=\"Train Loss\")\n",
    "plt.plot(val, label=\"Validation Loss\", linestyle=\"--\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.title(\"Best Model\\nlr=1e-4, layers=6, hidden=512\", fontsize=13)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "save_path = \"loss_plots/best_model_loss.png\"\n",
    "plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"Saved best model loss plot to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99798088-5680-487e-bce7-1d229603a817",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042acda3-3a06-4b87-9102-5c980f78ff38",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m运行具有“base (Python 3.10.16)”的单元格需要ipykernel包。\n",
      "\u001b[1;31m使用所需的包 <a href='command:jupyter.createPythonEnvAndSelectController'>创建 Python 环境</a>。\n",
      "\u001b[1;31m或使用命令“conda install -n base ipykernel --update-deps --force-reinstall”安装“ipykernel”"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f75b1b-0239-47ee-b35c-e4d28b954a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "model = Encoder(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    hidden_size=256,\n",
    "    num_heads=4,\n",
    "    num_layers=4,\n",
    "    intermediate_size=512,\n",
    "    max_len=128\n",
    ")\n",
    "model.load_state_dict(torch.load(\"encoder_lr1e-4_layers4_hs256.pt\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6b2ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw text\n",
    "with open(\"/ocean/projects/mth240012p/shared/data/raw_text.pkl\", \"rb\") as f:\n",
    "    raw_texts = pickle.load(f)\n",
    "\n",
    "story_embeddings = {}\n",
    "error_stories = []\n",
    "\n",
    "# Loop over each story\n",
    "for story_id, sequence in tqdm(raw_texts.items()):\n",
    "    try:\n",
    "        # Get full story text\n",
    "        story_text = \" \".join(sequence.data)\n",
    "        tokens = tokenizer(\n",
    "            story_text,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = tokens[\"input_ids\"].to(device)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].to(device)\n",
    "        attention_mask = tokens[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Get encoder hidden states before the MLM head\n",
    "        with torch.no_grad():\n",
    "            x = model.token_emb(input_ids) \\\n",
    "              + model.pos_emb(torch.arange(input_ids.size(1)).unsqueeze(0).to(device)) \\\n",
    "              + model.type_emb(token_type_ids)\n",
    "            for layer in model.layers:\n",
    "                x = layer(x, attention_mask)\n",
    "            x = model.norm(x)\n",
    "\n",
    "            # Mean pooling over seq_len\n",
    "            embedding = x.mean(dim=1).squeeze().cpu().numpy()\n",
    "            story_embeddings[story_id] = embedding\n",
    "\n",
    "    except Exception as e:\n",
    "        error_stories.append((story_id, str(e)))\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf74fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings\n",
    "with open(\"../results/embeddings/encoder_embeddings.pkl\", \"wb\") as f:\n",
    "    pickle.dump(story_embeddings, f)\n",
    "\n",
    "print(f\"Done. Saved {len(story_embeddings)} embeddings to ../results/embeddings/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6141546",
   "metadata": {},
   "source": [
    "Above is work done so far, the code under haven't sucessfully run once yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a66910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ridge_utils.DataSequence import DataSequence\n",
    "from ridge_utils.ziploader import ZipDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fefa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "with open(\"../results/embeddings/encoder_embeddings.pkl\", \"rb\") as f:\n",
    "    story_embeddings = pickle.load(f)  # dict: story_id -> np.array [D]\n",
    "\n",
    "# Load subject2\n",
    "subject = ZipDataLoader(\"/ocean/projects/mth240012p/shared/data/subject2.zip\")\n",
    "\n",
    "# Create DataSequence dict\n",
    "ds_dict = {}\n",
    "for sid in story_embeddings:\n",
    "    emb = story_embeddings[sid]\n",
    "    times = subject.stimuli[sid].data_times\n",
    "    tr_times = subject.stimuli[sid].tr_times\n",
    "    split_inds = subject.stimuli[sid].split_inds\n",
    "    if emb.shape[0] != len(times):\n",
    "        continue  \n",
    "    ds_dict[sid] = DataSequence(emb, split_inds, times, tr_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb791e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stories = subject.train_story_ids\n",
    "test_stories  = subject.test_story_ids\n",
    "\n",
    "X_train = np.concatenate([ds_dict[sid].chunksums(interp=\"lanczos\") for sid in train_stories])\n",
    "X_test  = np.concatenate([ds_dict[sid].chunksums(interp=\"lanczos\") for sid in test_stories])\n",
    "\n",
    "Y_train = np.concatenate([subject.responses[sid] for sid in train_stories])\n",
    "Y_test  = np.concatenate([subject.responses[sid] for sid in test_stories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f569fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ridge_utils.utils import zscore, make_delayed\n",
    "from ridge_utils.ridge import bootstrap_ridge\n",
    "\n",
    "X_train_z = zscore(X_train)\n",
    "Y_train_z = zscore(Y_train)\n",
    "X_test_z = zscore(X_test)\n",
    "Y_test_z = zscore(Y_test)\n",
    "\n",
    "delays = [0, 1, 2, 3]\n",
    "X_train_d = make_delayed(X_train_z, delays)\n",
    "X_test_d = make_delayed(X_test_z, delays)\n",
    "\n",
    "alphas = np.logspace(1, 4, 20)\n",
    "wt, test_corrs, val_alphas, allRcorrs, valinds = bootstrap_ridge(\n",
    "    X_train_d, Y_train_z, X_test_d, Y_test_z,\n",
    "    alphas=alphas,\n",
    "    nboots=10,\n",
    "    chunklen=10,\n",
    "    nchunks=2,\n",
    "    normalpha=True,\n",
    "    return_wt=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca060e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(test_corrs, bins=50)\n",
    "plt.xlabel(\"Test correlation\")\n",
    "plt.ylabel(\"Voxel count\")\n",
    "plt.title(\"Encoder Embedding Performance on Subject 2\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
